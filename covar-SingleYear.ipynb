{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary use case for Moisture Budgets\n",
    "\n",
    "## Monthly Mean Eddy Covariances from 6-hourly model output\n",
    "\n",
    "### PURPOSE: Calculate the monthly mean eddy covariances, U'Q' and V'Q'  from 6-hourly data\n",
    "\n",
    "    U,V are 6-hourly (lon,lat,lev) wind data on model sigma levels\n",
    "     Q   is 6-hourly specific humidity data on model sigma levels\n",
    " \n",
    "### BACKGROUND: \n",
    "    The vertically integrated monthly mean atmospheric moisture \n",
    "    budgets provide an accounting for the physical processes leading \n",
    "    to the net surface water flux, E-P (Evaporation minus Precipitation).\n",
    "    The physical processes can be time filtered in time into mean and \n",
    "    eddy terms and spatially into convergence and advection terms.  We \n",
    "    can also separate time anomalies and trends into those resulting \n",
    "    from changes in atmospheric moisture and those resulting from changes \n",
    "    in the atmospheric circulation.  This allows diagnostic evaluation\n",
    "    of the physical mechanisms of hydroclimate variability and change.\n",
    "    See:\n",
    "    \n",
    "    __Seager, R. and N. Henderson, 2013: Diagnostic computation of moisture \n",
    "    budgets in the ERA-Interim Reanalysis with reference to analysis of \n",
    "    CMIP-archived atmospheric model data. J. Climate, 26: 7876 - 7901__\n",
    "    \n",
    "    The most computationally expensive part of this calculation is the \n",
    "    calculation of the covariance terms, U*Q and V*Q since these quantities \n",
    "    are generally not included in the standard variables in the CMIP \n",
    "    archives.  Ideally they would be calculated for every time step of \n",
    "    the simulation. In the absence of these actual covariances, we must \n",
    "    compute an approximation from the 6-hourly model output that is standard \n",
    "    for CMIP.  Since most of the moisture is in the lower part of the \n",
    "    atmosphere where the topography plays a significant role, the horizontal \n",
    "    differencing and vertical integrals must be treated carefully.\n",
    "    \n",
    "    This is a test case for the calculation of the covariances using only \n",
    "    the NCAR/CCMS4 historical CMIP5 simulation. Only one ensemble member \n",
    "    is available, r6i1p1, but 1.5Tbytes of data must be processed to \n",
    "    calculate the monthly mean covariances.\n",
    "\n",
    "### DATA USED: \n",
    "    The CMIP5-CCSM-historical test data is located on cheyenne.ncar.edu:\n",
    "    \n",
    "    /glade/p/CMIP/CMIP5/output1/NCAR/CCSM4/historical/6hr/atmos/6hrLev/r6i1p1/latest/\n",
    "    \n",
    "    There are two forms of the ua,va and hus fields available, one set \n",
    "    on the model sigma vertical grid and the other interpolated to a reduced \n",
    "    set of pressure levels. We use the pressure level data since most modeling \n",
    "    groups do not provide data on the native vertical grid, but NCAR/CCMS4 \n",
    "    provides only U and V, Q is not available. I have submitted\n",
    "    a request, but they are still 'Looking into it'.\n",
    "    \n",
    "    This particular model has 6-hourly data from 1950-2005 on 26 levels for \n",
    "    only one ensemble member. They provide 4 files per model year and each \n",
    "    file for each variable is 2.1G.  Thus the data to be processed is\n",
    "    about 1.5Tb - just for the historical runs.\n",
    "\n",
    "### METHOD:  for all levels,latitudes and longitudes, \n",
    "    calculate <U'*Q'> = <U*Q> - <U>*<Q>\n",
    "\n",
    "### NOTATION:  \n",
    "\n",
    "     U  = 6-hourly U data \n",
    "    <U> = monthly mean U \n",
    "     U' = U - <U>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There are four CCSM4 6-hourly data files per year, and the names must reflect the time boundaries\n",
    "def ReadYear(syear,sdir,tdir,var):\n",
    "    start = {'JFM':'010100', 'AMJ':'040100', 'JAS':'070100', 'OND':'100100'}\n",
    "    stop  = {'JFM':'033118', 'AMJ':'063018', 'JAS':'093018', 'OND':'123118'}\n",
    "\n",
    "    ncfile = []\n",
    "    for season in ['JFM', 'AMJ', 'JAS', 'OND']:\n",
    "        ncfile.append(sdir+var+'/'+var+tdir+syear+start[season]+'-'+syear+stop[season]+'.nc')\n",
    "       \n",
    "    return ncfile   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment next line for cheyenne:\n",
    "#dir_base = '/glade/p/CMIP/CMIP5/output1/'\n",
    "\n",
    "# This is my test directory on local machine:\n",
    "dir_base = './'\n",
    "\n",
    "center = \"NCAR\"; model = \"CCSM4\"\n",
    "scenario = \"historical\"\n",
    "freq = \"6hr\"; realm = \"atmos\"; dtype = \"6hrLev\"\n",
    "\n",
    "nyears = 1\n",
    "start_year = 1960\n",
    "\n",
    "ddir = dir_base+center+'/'+model+'/'+scenario+'/'+freq+'/'+realm+'/'+dtype+'/'\n",
    "for edir in os.listdir(ddir):\n",
    "    for year in range(start_year,start_year+nyears):\n",
    "#        print('starting year',year)\n",
    "        syear = str(year)\n",
    "        sdir = ddir+edir+'/latest/'\n",
    "        tdir = '_6hrLev_'+model+'_'+scenario+'_'+edir+'_'\n",
    "        hus_files = ReadYear(syear,sdir,tdir,'hus')\n",
    "        ua_files  = ReadYear(syear,sdir,tdir,'ua')\n",
    "        va_files  = ReadYear(syear,sdir,tdir,'va')\n",
    "        \n",
    "        first = 1\n",
    "        for hf, uf in zip(hus_files, ua_files):\n",
    "            ds = xr.auto_combine([xr.open_dataset(hf), xr.open_dataset(uf)])\n",
    "            ds['qu'] = ds.hus*ds.ua\n",
    "            \n",
    "            qum = ds.qu.groupby('time.month').mean('time')\n",
    "            qmum = ds.hus.groupby('time.month').mean('time') * ds.ua.groupby('time.month').mean('time')\n",
    "            qdiff = qum-qmum\n",
    "#            print(qdiff.month)\n",
    "            if first:\n",
    "#                print('first')\n",
    "                qpup = qdiff\n",
    "                first = 0\n",
    "            else:\n",
    "#                print('next')\n",
    "                qpup = xr.concat([qpup,qdiff], dim='month')\n",
    "                \n",
    "        first = 1\n",
    "        for hf, vf in zip(hus_files, va_files):\n",
    "            ds = xr.auto_combine([xr.open_dataset(hf), xr.open_dataset(vf)])\n",
    "            ds['qv'] = ds.hus*ds.va\n",
    "            \n",
    "            qvm = ds.qv.groupby('time.month').mean('time')\n",
    "            qmvm = ds.hus.groupby('time.month').mean('time') * ds.va.groupby('time.month').mean('time')\n",
    "            qdiff = qvm-qmvm\n",
    "#            print(qdiff.month)\n",
    "            if first:\n",
    "#                print('first')\n",
    "                qpvp = qdiff\n",
    "                first = 0\n",
    "            else:\n",
    "#                print('next')\n",
    "                qpvp = xr.concat([qpvp,qdiff], dim='month')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arrays = [xr.DataArray(1, name='qpup'),xr.DataArray(1, name='qpvp')]\n",
    "dsm = xr.merge(arrays)  \n",
    "# but this Datset does not inherit the lon,lat,lev grids\n",
    "\n",
    "# so will do explicitly:\n",
    "# note that the new 'time' grid is in months and has lost knowledge of year - \n",
    "#    so will put in name of output file for now\n",
    "dsm = xr.Dataset({'lon': ('lon', ds.lon), 'lat': ('lat', ds.lat), 'lev': ('lev', ds.lev), \n",
    "                  'month':('month',qpup.month),\n",
    "                  'qpup': (['month','lev','lat','lon'], qpup), \n",
    "                  'qpvp': (['month','lev','lat','lon'], qpvp)})\n",
    "dsm.to_netcdf('covar'+syear+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,3))\n",
    "dp=dsm.qpvp.mean('month').sel(lev=1, method='nearest').plot()\n",
    "plt.title(r'surface <$V^{\\,\\prime} Q^{\\,\\prime}>$')\n",
    "plt.ylabel('latitude');plt.xlabel('longitude')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
